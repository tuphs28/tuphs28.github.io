---
layout: about
title: Home
permalink: /
subtitle: London

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: 

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
latest_posts: false
social: false # includes social icons at the bottom of the page
---

Hi, I'm Tom! My goal is to ensure advanced AI lives up to its potential to benefit humanity. My current research revolves around the unifying theme of safe and reliable AI. Specifically, I am interested in answering the following two questions:

1. Under what conditions do models learn to reason in a safe and reliable fashion?
2. How can we verify whether a model is reasoning in a safe and reliable manner?

To this end, my primary research interests are (i) mechanistic interpretability, (ii) reinforcement learning and (iii) world models. I am especially excited about research at the intersection of these topics.

I am currently a [MATS](https://www.matsprogram.org/) research scholar supervised by [Adria Garriga-Alonso](https://agarri.ga/). Until recently, I was also research assistant at Krueger AI Safety Lab supervised by [Prof David Krueger](https://davidscottkrueger.com/), and working with [Usman Anwar](https://uzman-anwar.github.io/) and [Stephen Chung](https://stephen-c.com/).  Previously, I was a MPhil student in Machine Learning and Machine Intelligence at the University of Cambridge, and a BSc student in Philosophy, Politics and Economics at LSE. I am currently actively looking for research opportunities and PhD positions so please reach out! 

